units: 96.0
activation_function: relu
learning_rate: 0.0007274208872666856
hidden_layers: 3.0
The amount of trained epochs are: 100
The loss function is: mean_squared_error
Model: "sequential_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense_4 (Dense)             (None, 96)                480       
                                                                 
 dense_5 (Dense)             (None, 96)                9312      
                                                                 
 dense_6 (Dense)             (None, 96)                9312      
                                                                 
 dense_7 (Dense)             (None, 2)                 194       
                                                                 
=================================================================
Total params: 19298 (75.38 KB)
Trainable params: 19298 (75.38 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
